{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load data and initialize chat engine\n",
    "docs = SimpleDirectoryReader(\"Sameer/\").load_data()\n",
    "index = VectorStoreIndex.from_documents(docs)\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=4000)\n",
    "user = \"Hassan\"\n",
    "chat_engine = index.as_chat_engine(\n",
    "    chat_mode=\"context\",\n",
    "    memory=memory,\n",
    "    system_prompt=(\n",
    "            f\"\"\"\n",
    "            Welcome to the HR chatbot, {user}!\n",
    "            Your job is to analyze {user}'s details and provide exact information accordingly.\n",
    "            Remember, every response will begin with your name, {user}, so user know the person behind the words.\n",
    "            Ensure that your responses are concise, appropriate, and maintain a professional tone.\n",
    "            If a query is beyond the scope of HR, politely apologize and refrain from providing the information.\n",
    "            \"\"\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "def langchain_query_executor(query):\n",
    "    response = chat_engine.chat(query)\n",
    "    return response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hello! Who are you?. And provide me all the names of the employees which works in our bank?\"\n",
    "response = langchain_query_executor(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"Mike\"\n",
    "\n",
    "system = f\"\"\" You are Human Resource Manager of Meezan Bank. \n",
    "            Your job is to analyze the {username} details and give valid information accordingly.\n",
    "            You are strictly not allowed to give someone information rather than {username}.\n",
    "            Make sure your answers should be conscise, appropriate and maintain a professional tone.\n",
    "            If a query is out of the scope of HR then simply apologize.\n",
    "        \"\"\"\n",
    "\n",
    "print(system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load data and initialize chat engine\n",
    "docs = SimpleDirectoryReader(\"Sameer/\").load_data()\n",
    "index = VectorStoreIndex.from_documents(docs)\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=4000)\n",
    "user = \"David\"\n",
    "chat_engine = index.as_chat_engine(\n",
    "    chat_mode=\"context\",\n",
    "    memory=memory,\n",
    "    system_prompt=(\n",
    "            f\"\"\" \n",
    " - You are a helpful HR manager at Meezan Bank Pakistan, who guides the employee named {user} on HR policies and other Affairs which relates to HR.\n",
    " - You have the data of the employee {user} in tabular form.\n",
    " - Your job is to answer the questions of the employee {user} step by step, for example `if your ask about just leave data then you first ask type of the leave (sick,annual,casual ). then show only specified type data only`.\n",
    "\n",
    "You have been given two documents.\n",
    "One document is about the policies and procedures of Meezan bank, use it to answer the questions when the questions are about the different policies and procedures.\n",
    "The other document is about the data of all the employees including {user} in tabular form. Use it when the questions are about that specific data.\n",
    "\n",
    "If {user} ask for a leave, then you should ask the employee which type of leaves they want.\n",
    "If {user} wants to submit the sick leave, then give {user} a short prayer message and tell them to send the sick leave application\n",
    "to the following email \"hr@meezan.com.\"\n",
    "If {user} ask for a casual or annual leave then you should ask in a friendly way if they are planning for holiday or travelling somewhere.\n",
    "If a user does not mention the date/dates for annual or casual leave then you must ask the date/dates for which they want the leave,\n",
    "and then compare those date with the following blackout dates\n",
    "blackout data: ```\n",
    "3rd may 2024 to 10th may 2024 (because of system maintenance and upgrade)\n",
    "3rd june 2024 to 20th june 2024(because of business season)\n",
    "3rd august 2024 to 10th august 2024(because of audit period)\n",
    "```\n",
    "If the employee's leaves dates clashes with the blackout dates then apologize and suggest alternative dates or just contact with HR by emailing the HR on the following email 'hr@meezan.com'.\n",
    "\n",
    "Your response must be friendly and the employee {user} should not feel like talking to a bot or robot .\n",
    "If a query is beyond the scope of HR, politely apologize and refrain from providing the information.\n",
    "Ensure that your responses are concise, appropriate, and maintain a professional tone.\n",
    "                 \n",
    "Keep the name {user} in your responses so that the response looks natural and personalized.\n",
    "Your responses should natural and human like.\n",
    "Keep your responses short and to the point.\n",
    "\n",
    "I want you to follow this example:\n",
    "\n",
    "User: Hi, I want to apply for a leave?\n",
    "Your response: Ok, What kind of leave do you want to apply for? \n",
    "Casual, Annual, Sick?\n",
    "\n",
    "User: Annual leave.\n",
    "Your response: {user} annual leave data is ...\n",
    "\n",
    "This is the kind of conversation I want to see between you and the user.\n",
    "\"\"\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "def langchain_query_executor(query):\n",
    "    response = chat_engine.chat(query)\n",
    "    return response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello David! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "query = \"Hi there!\"\n",
    "response = langchain_query_executor(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David casual leave data is as follows:\n",
      "- Total Casual Leave: 10 days\n",
      "- Utilized Casual Leave: 0 days\n",
      "- Remaining Casual Leave: 10 days\n",
      "\n",
      "Is there anything else you would like to know or do regarding your casual leave?\n"
     ]
    }
   ],
   "source": [
    "query = \"I want to see casual leave.\"\n",
    "response = langchain_query_executor(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David annual leave data is as follows:\n",
      "- Total Annual Leave: 14 days\n",
      "- Utilized Annual Leave: 5 days\n",
      "- Remaining Annual Leave: 9 days\n",
      "\n",
      "Do you have any specific dates in mind for your annual leave, or do you need assistance with planning your leave dates?\n"
     ]
    }
   ],
   "source": [
    "query = \"I want to see annual leave.\"\n",
    "response = langchain_query_executor(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
