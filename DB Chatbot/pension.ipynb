{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "current_time = time.time()\n",
    "current_date = datetime.utcfromtimestamp(current_time).strftime('%Y-%m-%d')\n",
    "\n",
    "# print(\"Current date:\", current_date)\n",
    "\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.2,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    openai_api_key=openai_api_key,\n",
    "    max_tokens=1000,\n",
    ")\n",
    "# Create a single memory instance for the entire conversation\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "\n",
    "user = \"Hassan\"\n",
    "gender = \"male\"\n",
    "designation = \"employee\"\n",
    "salary = \"Rs. 50,000\"\n",
    "job_status = \"permanent\"\n",
    "end_date = \"present\"\n",
    "\n",
    "petrol_claim = \"25 Liter per month\"\n",
    "mobile_claim = \"Rs 500 per month\"\n",
    "house_finance = \"upto 1 million with 6% interest per annum\"\n",
    "auto_finance = \"upto 1 million with 5% interest per annum\"\n",
    "insurance_type = \"Basic\"\n",
    "health_insurance_details = \"Coverage up to 4K units with 400 deductible.\"\n",
    "accidental_death_insurance_details = \"coverage of 10K units.\"\n",
    "\n",
    "\n",
    "# user = \"Hassan\"\n",
    "# gender = \"male\"\n",
    "# designation = \"employee\"\n",
    "# job_status = \"probation\"\n",
    "joining_date = \"2000-March-22\"\n",
    "# end_date = \"2024-June-22\"\n",
    "\n",
    "# petrol_claim = \"-\"\n",
    "# mobile_claim = \"-\"\n",
    "# house_finance = \"-\"\n",
    "# auto_finance = \"-\"\n",
    "# insurance_type = \"-\"\n",
    "# health_insurance_details = \"-\"\n",
    "# accidental_death_insurance_details = \"-\"\n",
    "\t\n",
    "current_date = datetime.utcfromtimestamp(current_time).strftime('%Y-%m-%d')\n",
    "\n",
    "def generate_response(input_message, model, memory):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"\n",
    "         You are Hira, a friendly female HR of Meezan Bank of Pakistan. Your role is to evaluate the pension based on their information.\n",
    "        The current date is {current_date}\n",
    "\n",
    "        {user} Profile:\n",
    "            - Gender: {gender}.\n",
    "            - Designation: {designation}.\n",
    "            - Job Status: {job_status}.\n",
    "            - Joining Date: {joining_date}.\n",
    "            - Current Salary: {salary}.\n",
    "\n",
    "\n",
    "        In this part, you will inform the {user} about their eligibility for pension based on their job status and the salary.\n",
    "\n",
    "        The {user} job status is {job_status}. After checking the job status proceed with following point:\n",
    "        - If {user}'s job status is permanent, inform them that you are qualified for the pension.\n",
    "            1- Here is how you calculate the pension.\n",
    "                1.1- You already know the joining date of the user now check the current date and evaluate that user has spend 20 years or not in the bank.\n",
    "                1.2- You have already know the user information so you have to evaluate the pension based on their job status and the salary.\n",
    "                1.3- If {user} already spent 20 years in the company then calculate the pension according to the salary and inform him/her that its not an actual pension \\n\n",
    "                    its just an estimated value. You have to verify this from the HR in person.\n",
    "        - If {user}'s job status is probation then inform him that your probationary period will be 90 days and after your probationary period you have to spent atleast 20 years in the company to get pension.\n",
    "        \n",
    "        - You have to inform the employee who is on probation period that you are not eligible for the pension.\n",
    "\n",
    "\n",
    "        \n",
    "        You are strictly not allowed to talk on off topic.\n",
    "        Your response should be precise and to the point.\n",
    "        Stick to this professional tone.  \n",
    "        Make sure you have asked all the questions that mentioned above before proceeding further queries.\n",
    "        \"\"\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", f\"{input_message}\"),\n",
    "    ])\n",
    "\n",
    "    chain = (\n",
    "        RunnablePassthrough.assign(\n",
    "            history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\")\n",
    "        )\n",
    "        | prompt\n",
    "        | model\n",
    "    )\n",
    "\n",
    "    inputs = {\"input\": input_message}\n",
    "    response = chain.invoke(inputs)\n",
    "\n",
    "    # Save the context for future interactions\n",
    "    memory.save_context(inputs, {\"output\": response.content})\n",
    "    memory.load_memory_variables({})\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Prompt 1\n",
    "prompt = \"Hi\"\n",
    "print(generate_response(prompt, chat, memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are Hassan.\n"
     ]
    }
   ],
   "source": [
    "# Prompt 1\n",
    "prompt = \"Who am I?\"\n",
    "print(generate_response(prompt, chat, memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As per your job status being permanent, you are qualified for the pension. To calculate the pension, we need to verify if you have spent 20 years in the company. If you have, then we can estimate the pension based on your salary.\n"
     ]
    }
   ],
   "source": [
    "# Prompt 1\n",
    "prompt = \"What should be my pension if I got retired.\"\n",
    "print(generate_response(prompt, chat, memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! Since you have confirmed that you have spent 20 years in the company, we can estimate your pension based on your salary. Your current salary is Rs. 50,000. I will calculate the estimated pension for you. Please wait for a moment.\n"
     ]
    }
   ],
   "source": [
    "# Prompt 1\n",
    "prompt = \"yes\"\n",
    "print(generate_response(prompt, chat, memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your salary of Rs. 50,000 and 20 years of service, the estimated pension amount is Rs. 25,000. Please note that this is just an estimated value. For the actual pension amount, you will need to verify with the HR department in person.\n"
     ]
    }
   ],
   "source": [
    "# Prompt 1\n",
    "prompt = \"Ok\"\n",
    "print(generate_response(prompt, chat, memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
